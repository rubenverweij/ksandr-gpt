{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4848090",
   "metadata": {},
   "source": [
    "# KSANDR-GPT\n",
    "\n",
    "Prestatie test van een twee taalmodellen met een CPU en GPU implementatie:\n",
    "\n",
    "1. meta-llama/Llama-4-Scout-17B-16E-Instruct\n",
    "2. meta-llama/Llama-3.1-70B-Instruct\n",
    "3. Meta Llama 3.1 8B Instruct\n",
    "4. zephyr-7b-beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f423af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 4070 Ti'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from onprem import LLM\n",
    "import torch\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5976b944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 4070 Ti, compute capability 8.9, VMM: yes\n",
      "llama_model_load_from_file_impl: using device CUDA0 (NVIDIA GeForce RTX 4070 Ti) - 11038 MiB free\n",
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from C:\\Users\\info\\onprem_data\\models\\zephyr-7b-beta.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = huggingfaceh4_zephyr-7b-beta\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 4.07 GiB (4.83 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_swa_pattern    = 1\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = huggingfaceh4_zephyr-7b-beta\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: PAD token        = 2 '</s>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  29 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  30 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  31 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: layer  32 assigned to device CUDA0, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 0 others) cannot be used with preferred buffer type CUDA_Host, using CPU instead\n",
      "load_tensors: offloading 32 repeating layers to GPU\n",
      "load_tensors: offloading output layer to GPU\n",
      "load_tensors: offloaded 33/33 layers to GPU\n",
      "load_tensors:        CUDA0 model buffer size =  4095.05 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =    70.31 MiB\n",
      "...............................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 3900\n",
      "llama_context: n_ctx_per_seq = 3900\n",
      "llama_context: n_batch       = 1024\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: freq_base     = 10000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (3900) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:  CUDA_Host  output buffer size =     0.12 MiB\n",
      "create_memory: n_ctx = 3904 (padded)\n",
      "llama_kv_cache_unified: kv_size = 3904, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1, padding = 32\n",
      "llama_kv_cache_unified: layer   0: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   1: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   2: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   3: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   4: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   5: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   6: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   7: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   8: dev = CUDA0\n",
      "llama_kv_cache_unified: layer   9: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  10: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  11: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  12: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  13: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  14: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  15: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  16: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  17: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  18: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  19: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  20: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  21: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  22: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  23: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  24: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  25: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  26: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  27: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  28: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  29: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  30: dev = CUDA0\n",
      "llama_kv_cache_unified: layer  31: dev = CUDA0\n",
      "llama_kv_cache_unified:      CUDA0 KV buffer size =   488.00 MiB\n",
      "llama_kv_cache_unified: KV self size  =  488.00 MiB, K (f16):  244.00 MiB, V (f16):  244.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 2\n",
      "llama_context: max_nodes = 65536\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
      "llama_context:      CUDA0 compute buffer size =   283.63 MiB\n",
      "llama_context:  CUDA_Host compute buffer size =    15.63 MiB\n",
      "llama_context: graph nodes  = 1094\n",
      "llama_context: graph splits = 2\n",
      "CUDA : ARCHS = 890 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.name': 'huggingfaceh4_zephyr-7b-beta', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.padding_token_id': '2'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "# llm = LLM(model_url=\"Llama-4-Scout-17B-16E-Instruct-UD-Q2_K_XL.gguf\", model_download_path=\"C:/Users/info/onprem_data/models/\", n_gpu_layers=-1, embedding_model_kwargs={'device':'cuda'}) \n",
    "# llm = LLM(default_model='llama', n_gpu_layers=-1, embedding_model_kwargs={'device':'cuda'})\n",
    "llm = LLM(n_gpu_layers=-1, embedding_model_kwargs={'device':'cuda'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650747f7",
   "metadata": {},
   "source": [
    "Encodeer documenten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "167dacb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (4190344804.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mllm.load_vectordb(\"C:\\Users\\info\\onprem_data\\vectordb\\dense\")\u001b[39m\n                      ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "llm.load_vectordb(\"C:\\Users\\info\\onprem_data\\vectordb\\dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4574a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to existing vectorstore at C:\\Users\\info\\onprem_data\\vectordb\\dense\n",
      "Loading documents from docs/txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading new documents: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new documents to process\n",
      "Split into 0 chunks of text (max. 500 chars each for text; max. 2000 chars for tables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm.ingest(source_directory=\"docs/txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13db521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\info\\AppData\\Local\\Temp\\ipykernel_12996\\220027322.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  llm.load_vectordb().update_document(document_id='c9afbd27-6165-488d-82b0-f0f1e6827d24', document=\"C:\\Datapreds\\projects\\ksandr-gpt\\docs\\txt\\distribution_transformers_en_4.txt\")\n",
      "C:\\Users\\info\\AppData\\Local\\Temp\\ipykernel_12996\\220027322.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  llm.load_vectordb().update_document(document_id='c9afbd27-6165-488d-82b0-f0f1e6827d24', document=\"C:\\Datapreds\\projects\\ksandr-gpt\\docs\\txt\\distribution_transformers_en_4.txt\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# llm.load_vectordb().get_by_ids(['c9afbd27-6165-488d-82b0-f0f1e6827d24'])\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_vectordb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mc9afbd27-6165-488d-82b0-f0f1e6827d24\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDatapreds\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mprojects\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mksandr-gpt\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mdocs\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[33;43mxt\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mdistribution_transformers_en_4.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Datapreds\\projects\\ksandr-gpt\\venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:1076\u001b[39m, in \u001b[36mChroma.update_document\u001b[39m\u001b[34m(self, document_id, document)\u001b[39m\n\u001b[32m   1069\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_document\u001b[39m(\u001b[38;5;28mself\u001b[39m, document_id: \u001b[38;5;28mstr\u001b[39m, document: Document) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1070\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Update a document in the collection.\u001b[39;00m\n\u001b[32m   1071\u001b[39m \n\u001b[32m   1072\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03m        document_id: ID of the document to update.\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m        document: Document to update.\u001b[39;00m\n\u001b[32m   1075\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1076\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdocument_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Datapreds\\projects\\ksandr-gpt\\venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:1089\u001b[39m, in \u001b[36mChroma.update_documents\u001b[39m\u001b[34m(self, ids, documents)\u001b[39m\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, ids: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], documents: \u001b[38;5;28mlist\u001b[39m[Document]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1080\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Update a document in the collection.\u001b[39;00m\n\u001b[32m   1081\u001b[39m \n\u001b[32m   1082\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1087\u001b[39m \u001b[33;03m        ValueError: If the embedding function is not provided.\u001b[39;00m\n\u001b[32m   1088\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     text = [\u001b[43mdocument\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_content\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m   1090\u001b[39m     metadata = [document.metadata \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m   1091\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "# llm.load_vectordb().get_by_ids(['c9afbd27-6165-488d-82b0-f0f1e6827d24'])\n",
    "llm.load_vectordb().update_document(document_id='c9afbd27-6165-488d-82b0-f0f1e6827d24', document=\"C:\\Datapreds\\projects\\ksandr-gpt\\docs\\txt\\distribution_transformers_en_4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e95961",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "llm.ask(\"How many documents are ingested by the user?\", score_threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b843c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.ask(\"Kunnen transformatoren verschillende overbrengingsverhoudingen hebben?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c1ead7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 230 prefix-match hit, remaining 238 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The provided context does not include any ingested documents. The given pieces of context only provide information related to transportation, assembly, commissioning, and maintenance activities after the unit's release from the factory. It also mentions some certificates, including TÜV ISO 9001 for quality and performance, TÜV ISO 14001 for environment, and TÜV ISO 45001 for occupational safety. However, there is no document mentioned as the longest. Without further context or information, it's impossible to determine which document is the longest. If additional details about ingested documents are provided, an accurate answer can be given."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     410.63 ms\n",
      "llama_perf_context_print: prompt eval time =     219.28 ms /   238 tokens (    0.92 ms per token,  1085.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1641.53 ms /   140 runs   (   11.73 ms per token,    85.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1961.74 ms /   378 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The provided context includes three documents: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 467 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) a document providing an overview of transport, assembly, commissioning, and maintenance activities after delivery to the client, where more detailed information can be requested from SBG Neumark; 2) a statement about certifications, including TÜV ISO 9001 for quality and performance, TÜV ISO 14001 for environment, and TÜV ISO 45001 for occupational safety, which are renewed regularly; and 3) instructions for handling fluids from the exhaust unit, requiring approximately 0.2 liters to be withdrawn from the drain system, depressurizing it, and then filling it as described in paragraph 4.5. Based on the length of the provided context, the longest document seems to be the first one, but without knowing its exact length, we cannot confirm this statement. However, we can assume that it may contain more information compared to the other two documents combined."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     410.63 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    2405.33 ms /   207 runs   (   11.62 ms per token,    86.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    2555.10 ms /   208 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The provided context consists of three blocks of text"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 467 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", delimited by three backticks each. The first block describes the purpose of a document and mentions that additional information is available upon request. It does not specify any certifications for the document.\n",
      "\n",
      "The second block lists multiple certifications, including TÜV ISO 9001, TÜV ISO 14001, and TÜV ISO 45001, but it doesn't provide further context about these documents or their length.\n",
      "\n",
      "The third block describes a specific task related to the unit's transportation, assembly, commissioning, and maintenance activities. It mentions taking a certain amount of fluid from an outlet and continuing with a previously described process in paragraph 4.5. This block does not mention any certifications or document lengths.\n",
      "\n",
      "Based on the provided context, it is impossible to summarize all the documents mentioned and determine which one is the longest, as no specific information about their length or content is given."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     410.63 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    2488.29 ms /   215 runs   (   11.57 ms per token,    86.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    2635.99 ms /   216 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The provided context includes three certifications,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 467 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TÜV ISO 9001 for quality and performance, TÜV ISO 14001 for environment, and TÜV ISO 45001 for occupational safety. These certificates are renewed regularly to ensure compliance with the respective standards. The longest document among these is not specified in the provided context.\n",
      "\n",
      "The remaining text provides technical information related to transportation, assembly, commissioning, and maintenance activities after delivery of the unit. The instruction to take around 0.2 liters from the drainage system, vent the filling chamber, and fill it as described in paragraph 4.5 stands out in this context.\n",
      "\n",
      "Overall, based on the given context, there is no document that can be considered significantly longer than others. The context mainly focuses on providing technical details about the unit's operation and maintenance rather than documentation or manuals."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     410.63 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    2231.93 ms /   193 runs   (   11.56 ms per token,    86.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2360.29 ms /   194 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The given context consists of three blocks"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 467 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " delimited by backticks. The first block provides an overview of post-delivery activities related to transportation, assembly, commissioning, and maintenance, with detailed information available upon request from SBG Neumark. The second block mentions certificates for quality, environment, and occupational safety, which are renewed on a regular basis. The third block describes a specific action required during an operation, where approximately 0.2 liters should be taken from the discharge system, vent the filling chamber, and fill it as described in paragraph 4.5. In terms of length, the first block seems to be the longest, as it provides an overview of multiple activities and mentions detailed information available upon request. However, the exact lengths would require measuring the number of characters or words in each block."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     410.63 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    2025.06 ms /   175 runs   (   11.57 ms per token,    86.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    2138.79 ms /   176 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The provided context consists of three blocks"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 467 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of text, delimited by triple backticks. These blocks provide information about transportation, assembly, commissioning, and maintenance activities after delivery to the customer, as well as certifications related to quality, environment, and occupational safety. The first block is from a manufacturer's document and provides detailed information about hermetically sealed or gas-cushioned units, free breathing with conservator, and OLTC units. The second block lists several ISO certifications that are renewed regularly for quality, environment, and occupational safety. The third block provides specific instructions regarding the handling of a small amount of fluid from a drainage system, which involves taking out 0.2 liters, venting the valve, and then proceeding as described in paragraph 4.5. Based on the length of the blocks, it can be seen that the first block is the longest, providing detailed information about various unit types. The other two blocks are shorter and mainly focused on certifications and specific instructions."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     410.63 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    2485.57 ms /   215 runs   (   11.56 ms per token,    86.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    2629.09 ms /   216 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The text mentions three certifications"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 467 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - TÜV ISO 9001, TÜV ISO 14001, and TÜV ISO 45001. These certifications are related to quality and performance (TÜV ISO 9001), environment (TÜV ISO 14001), and occupational safety (TÜV ISO 45001). The text mentions that all these certificates are regularly renewed. However, the text does not provide any information about the length of these documents. Without further context or details, it is impossible to determine which document is the longest.\n",
      "\n",
      "The rest of the text seems to describe technical specifications related to transportation, assembly, commissioning, and maintenance activities after unit delivery. It provides information about hermitically sealed, gas cushion-sealed, free breathing with conservator, and OLTC units. The longest section in this text is related to the procedures for taking approximately 0.2 liters from the exhaust outlet, releasing it from the buffer tank, and filling it as described in paragraph 4.5.\n",
      "\n",
      "Therefore, based on the given context, the longest section seems to be related to the technical specifications for maintenance activities after unit delivery, rather than the certifications mentioned at the beginning of the text."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     410.63 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    3288.87 ms /   284 runs   (   11.58 ms per token,    86.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    3489.69 ms /   285 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The provided context consists of two documents,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 467 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " both in German. The first document describes transportation, assembly, commissioning, and maintenance activities after delivery to the customer. It mentions that more detailed information is available upon request from SBG Neumark. This document covers topics such as hermetically sealed, gas cushion-sealed, free breathing with conservator, and OLTC units.\n",
      "\n",
      "The second document lists several certifications: TÜV ISO 9001 for quality and performance, TÜV ISO 14001 for environment, and TÜV ISO 45001 for occupational safety. It also mentions that these certificates are renewed regularly.\n",
      "\n",
      "In terms of length, the first document is longer as it describes various tasks to be performed after delivery, while the second document focuses on certifications. The exact word count cannot be determined without knowing the total number of words in each document."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     410.63 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    2312.85 ms /   198 runs   (   11.68 ms per token,    85.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    2457.49 ms /   199 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7 s ± 396 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "llm.ask(\"Please summarise the ingested documents, which document is the longest?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a360fe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 230 prefix-match hit, remaining 446 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "De documenten geven inzicht in de transport-, montage-, inbedrijfstellings- en onderhoudswerkzaamheden van transformatoren na levering aan de klant. Hierbij wordt meer gedetailleerde informatie op aanvraag verkregen bij SBG Neumark. In het geval van hermetisch gesloten of met gaskussens afgesloten, vrij ademende (met conservator) en laastschakelaar-units vindt u de informatie hieronder in de tekst. De documenten worden bedoeld om een overzicht te geven van deze werkzaamheden. Welke documenten zijn dan handig voor het beheer en onderhoud van transformatoren?"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     410.63 ms\n",
      "llama_perf_context_print: prompt eval time =     253.16 ms /   446 tokens (    0.57 ms per token,  1761.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2018.17 ms /   174 runs   (   11.60 ms per token,    86.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    2391.78 ms /   620 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Welke documenten geven inzicht in de bediening van transformatoren?',\n",
       " 'answer': '\\nDe documenten geven inzicht in de transport-, montage-, inbedrijfstellings- en onderhoudswerkzaamheden van transformatoren na levering aan de klant. Hierbij wordt meer gedetailleerde informatie op aanvraag verkregen bij SBG Neumark. In het geval van hermetisch gesloten of met gaskussens afgesloten, vrij ademende (met conservator) en laastschakelaar-units vindt u de informatie hieronder in de tekst. De documenten worden bedoeld om een overzicht te geven van deze werkzaamheden. Welke documenten zijn dan handig voor het beheer en onderhoud van transformatoren?',\n",
       " 'source_documents': [Document(id='c9afbd27-6165-488d-82b0-f0f1e6827d24', metadata={'document_title': '', 'extension': 'txt', 'markdown': False, 'ocr': False, 'page': -1, 'source': 'c:/Datapreds/projects/ksandr-gpt/docs/txt/Bedieningshandleiding_B2021_DT_NL_1.txt', 'table': False, 'table_captions': '', 'score': 0.6511597633361816}, page_content='Het document is bedoeld om een overzicht te geven van de transport-, montage-, inbedrijfstellings- en\\nonderhoudswerkzaamheden na levering aan de klant. Meer gedetailleerde informatie is op aanvraag verkrijgbaar bij\\nSBG Neumark. Informatie over hermetisch gesloten of met gaskussen afgesloten, vrij ademende (met conservator) en\\nlastschakelaar-units vindt u hieronder in de tekst.\\nLet erop dat wanneer dit wordt aangegeven, de informatie voor het juiste transformatortype wordt gebruikt.'),\n",
       "  Document(id='0e7d14c2-1642-48d3-8d29-f3866e6688de', metadata={'document_title': '', 'extension': 'txt', 'markdown': False, 'ocr': False, 'page': -1, 'source': 'c:/Datapreds/projects/ksandr-gpt/docs/txt/Bedieningshandleiding_B2021_DT_NL_3.txt', 'table': False, 'table_captions': '', 'score': 0.6460480690002441}, page_content='4.6 Olie bijvullen\\n\\t\\t Na voltooiing van de werkzaamheden moeten de transformatoren worden gevuld.\\n\\t\\t     Ga bij hermetisch gesloten units als volgt te werk:\\n\\t\\t     4.6.1 Schroef de dop van de vulbuis.\\n\\t\\t     4.6.2 Vul de transformatoren en de vulbuis met olie.\\n\\t\\t     4.6.3 Ontluchten van de doorvoeringen.\\n\\t\\t     4.6.4. Vul de vulbuis opnieuw (tot aan de rand) en sluit hem af met het deksel. Zorg ervoor dat alle\\n\\t\\t\\t           andere units zijn gevuld (indien nodig) en sluit ze tot slot af.'),\n",
       "  Document(id='e42cd66a-0bf2-4474-853c-39afa17259d4', metadata={'document_title': '', 'extension': 'txt', 'markdown': False, 'ocr': False, 'page': -1, 'source': 'c:/Datapreds/projects/ksandr-gpt/docs/txt/Bedieningshandleiding_B2021_DT_NL_1.txt', 'table': False, 'table_captions': '', 'score': 0.6169207096099854}, page_content='wikkelingen en de olie worden berekend voor elk keteltype. Om deze reden adviseren wij om na levering van de\\n   transformator, de olievuldop NIET te openen, te ontluchten of de doorvoeringen te ontluchten.\\n   Voor alle werkzaamheden waarbij de transformatoren moeten worden geopend, bijv. installatie van een overdrukventiel\\n   of andere bewakingsapparatuur, de vervanging van doorvoeringen en/of afdichtingen, neem dan de aanwijzingen in'),\n",
       "  Document(id='885c2314-fc36-4df8-bad1-7449738b052a', metadata={'document_title': '', 'extension': 'txt', 'markdown': False, 'ocr': False, 'page': -1, 'source': 'c:/Datapreds/projects/ksandr-gpt/docs/txt/Bedieningshandleiding_B2021_DT_NL_1.txt', 'table': False, 'table_captions': '', 'score': 0.6142003536224365}, page_content='3.3.3 Plaats de ontluchter.\\n\\t\\t      3.3.4 Vul het oliereservoir van de ontluchter tot het gewenste peil (oliemarkeringen aanwezig).\\n   3.4 Aard de transformator aan de aardingsschroef.')]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.ask(\"Welke documenten geven inzicht in de bediening van transformatoren?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0494cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "###CPU\n",
    "start_time = time.time()\n",
    "a = torch.ones(4000,4000)\n",
    "for _ in range(10000):\n",
    "    a += a\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('CPU time = ',elapsed_time)\n",
    "\n",
    "###GPU\n",
    "torch.cuda.synchronize() \n",
    "start_time = time.time()\n",
    "b = torch.ones(4000,4000).cuda()\n",
    "for _ in range(30000):\n",
    "    b += b\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('GPU time = ',elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d625b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "llm = Llama(model_path=\"C:/Users/info/onprem_data/models/zephyr-7b-beta.Q4_K_M.gguf\", n_gpu_layers=30, n_ctx=3584, n_batch=521, verbose=True)\n",
    "# adjust n_gpu_layers as per your GPU and model\n",
    "output = llm(\"Q: Name the planets in the solar system? A: \", max_tokens=32, stop=[\"Q:\", \"\\n\"], echo=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14949145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
